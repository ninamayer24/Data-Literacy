{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "043fb08f",
   "metadata": {},
   "source": [
    "#### Merging the datasets\n",
    "\n",
    "The script merges the bridge dataset with the GDP data and population data. We want to include further information on the individual districts. We are going to combine cities (`Kreisfreie Stadt`) and their respective districts (`Kreis`). In the end, we add the following columns: \n",
    "- `GDP 2022`\n",
    "- `Bevölkerung (insgesamt)`\n",
    "- `Fläche pro Kreis (qkm)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d6c93e9-272e-47ac-979f-5856a071bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libaries\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2ba41acc-b7f6-4735-88c5-6917164b53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data_bridges = pd.read_csv('../data/filled_bridge_statistic_germany.csv', sep=';')\n",
    "data_gdp = pd.read_excel(\"../data/gdp_dataset.xlsx\", sheet_name= \"1.1\", skiprows= 4)\n",
    "data_population = pd.read_excel(\"../data/population_dataset.xlsx\", sheet_name= \"Kreisfreie Städte u. Landkreise\", skiprows= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49f89424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bebd0d",
   "metadata": {},
   "source": [
    "Because we want to look at the districts (`Kreise`), we delete the states. Furthermore, all rows which does not contain a value in the column `Kreis` are deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21a26f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data to modify it\n",
    "data_gdp_modified = data_gdp.copy()\n",
    "data_population_modified = data_population.copy()\n",
    "\n",
    "# deleting rows without an entry in NUTS 3 (district)\n",
    "data_gdp_modified = data_gdp_modified[\n",
    "    data_gdp_modified['NUTS 3'].notna() & (data_gdp_modified['NUTS 3'] != '')\n",
    "]\n",
    "\n",
    "data_population_modified = data_population_modified[\n",
    "    data_population_modified['NUTS3'].notna() & (data_population_modified['NUTS3'] != '')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2260c0",
   "metadata": {},
   "source": [
    "We have to normalize the names of the districts because they do not correspond to the ones we are using in our bridge data set (and for the visualisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8742ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts contained only in population data: {'Unterfranken', 'Schwaben', 'Mittelfranken'}\n",
      "District contained only in GDP data: set()\n",
      "Districts contained only in bridge data: {'Eisenach'}\n",
      "Districts contained only in bridge data: set()\n",
      "Districts not contained in bridge data: set()\n",
      "Number unique districts POPULATION: 375 (total: 400)\n",
      "Number unique districts GDP: 375 (total: 400)\n",
      "Number unique districts BRIDGES: 375\n",
      "Districts that are not unique: ['Bayreuth', 'Karlsruhe', 'Regensburg', 'Rostock', 'Bamberg', 'München', 'Coburg', 'Hof', 'Rosenheim', 'Ansbach', 'Fürth', 'Passau', 'Landshut', 'Kassel', 'Würzburg', 'Kaiserslautern', 'Augsburg', 'Aschaffenburg', 'Osnabrück', 'Leipzig', 'Offenbach', 'Bremen', 'Oldenburg', 'Schweinfurt', 'Heilbronn']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# function to normalize district names\n",
    "# @param name: district name (string)\n",
    "# @return: normalized district name (string)\n",
    "def normalize_name(name):\n",
    "    # check if NaN\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    \n",
    "    # convert to lower case\n",
    "    name = name.lower()\n",
    "\n",
    "    # remove space around hyphen\n",
    "    name = re.sub(r'\\s*-\\s*', '-', name)\n",
    "\n",
    "    # remove commas and full stops\n",
    "    name = name.replace(',', '')\n",
    "    name = name.replace('.', '')\n",
    "\n",
    "    # remove special keywords\n",
    "    name = re.sub(r'\\b(landkreis|kreisfreie stadt|stadt|regierungsbezirk|universitätsstadt|wissenschaftsstadt|landeshauptstadt|reg-bez|kfr|hansestadt|stadtkreis|klingenstadt|freie und hansestadt)\\b', '', name)\n",
    "    name = re.sub(r'(?<!-)\\bkreis\\b', '', name) # kreis nur wenn es allein steht\n",
    "\n",
    "    # remove bracket additions\n",
    "    # name = re.sub(r'\\([^)]*\\)', '', name)\n",
    "\n",
    "    # remove leading/trailing spaces\n",
    "    name = name.strip()\n",
    "\n",
    "    # reduce multiple space character to one\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "\n",
    "    # convert to upper case\n",
    "    name = name.title()\n",
    "\n",
    "    # make 'Am', 'An', 'Im', 'Auf', 'Vom', 'Zum', 'Zur' lowercase when surrounded by spaces\n",
    "    name = re.sub(r'\\b(Am|An|Im|Auf|Vom|Zum|Zur|Und|Der|In|Bei|Vom|Von|Zu|Mit|Aus|Auf)\\b', lambda m: m.group(0).lower(), name)\n",
    "\n",
    "    # special cases\n",
    "    name = re.sub (r'Oldenburg \\(Oldenburg\\)', 'Oldenburg', name)\n",
    "    name = re.sub ('Saarbrücken Regionalverband', 'Regionalverband Saarbrücken', name)\n",
    "    name = re.sub ('St Wendel', 'St. Wendel', name)\n",
    "    name = re.sub ('Märkischer', 'Märkischer Kreis', name)\n",
    "    name = re.sub ('Rheinisch-Bergischer', 'Rheinisch-Bergischer Kreis', name)\n",
    "    name = re.sub ('Oberbergischer', 'Oberbergischer Kreis', name)\n",
    "    name = re.sub ('Neustadt/Weinstrasse','Neustadt an der Weinstraße', name)\n",
    "    name = re.sub ('Frankfurt Main', 'Frankfurt am Main', name)\n",
    "    name = re.sub ('Hagen der Fernuniversität', 'Hagen', name)\n",
    "    name = re.sub ('Neustadt Adaisch-Bad Windsheim', 'Neustadt a.d. Aisch-Bad Windsheim', name)\n",
    "    name = re.sub ('Neustadt Adwaldnaab', 'Neustadt a.d. Waldnaab', name)\n",
    "    name = re.sub ('Landau In Der Pfalz', 'Landau in der Pfalz', name)\n",
    "    name = re.sub ('Kassel Documenta-', 'Kassel', name)\n",
    "    name = re.sub ('Neumarkt Idopf', 'Neumarkt i.d. OPf.', name)\n",
    "    name = re.sub ('Offenbach am Main', 'Offenbach', name)\n",
    "    name = re.sub ('Bremerhaven', 'Bremen', name)\n",
    "    name = re.sub ('Weiden Idopf', 'Weiden i.d. OPf.', name)\n",
    "    name = re.sub ('Dillingen Addonau', 'Dillingen a.d. Donau', name)\n",
    "    name = re.sub ('Pfaffenhofen Adilm', 'Pfaffenhofen a.d. Ilm', name)\n",
    "    name = re.sub ('Mühldorf Ainn', 'Mühldorf a. Inn', name)\n",
    "    name = re.sub ('Pfaffenhofen Ad Ilm', 'Pfaffenhofen a.d. Ilm', name)\n",
    "    name = re.sub ('Neustadt Ad Waldnaab', 'Neustadt a.d. Waldnaab', name)\n",
    "    name = re.sub ('Neustadt Ad Aisch-Bad Windsheim', 'Neustadt a.d. Aisch-Bad Windsheim', name)\n",
    "    name = re.sub ('Dillingen Ad Donau', 'Dillingen a.d. Donau', name)\n",
    "    name = re.sub ('Weiden Id Opf', 'Weiden i.d. OPf.', name)\n",
    "    name = re.sub ('Wunsiedel Ifichtelgebirge', 'Wunsiedel i. Fichtelgebirge', name)\n",
    "    name = re.sub ('Neumarkt Id Opf', 'Neumarkt i.d. OPf.', name)\n",
    "    name = re.sub ('Mühldorf A Inn', 'Mühldorf a. Inn', name)\n",
    "    name = re.sub ('Wunsiedel I Fichtelgebirge', 'Wunsiedel i. Fichtelgebirge', name)\n",
    "\n",
    "    return name\n",
    "\n",
    "df_pop = data_population_modified.copy()\n",
    "df_gdp = data_gdp_modified.copy()\n",
    "df_bridges = data_bridges.copy()\n",
    "\n",
    "# ---------- district name normalisation on the datasets ----------\n",
    "# population data\n",
    "df_pop['Kreisfreie Städte und Landkreise'] = df_pop['Kreisfreie Städte und Landkreise'].apply(normalize_name)\n",
    "# GDP data\n",
    "df_gdp['Gebietseinheit'] = df_gdp['Gebietseinheit'].apply(normalize_name)\n",
    "# bridge data\n",
    "df_bridges['Kreis'] = df_bridges['Kreis'].apply(normalize_name)\n",
    "\n",
    "# ---------- check whether both dataset contain the same district names and correct for it ----------\n",
    "print(f\"Districts contained only in population data: {set(df_pop['Kreisfreie Städte und Landkreise']) - set(df_gdp['Gebietseinheit'])}\")\n",
    "print(f\"District contained only in GDP data: {set(df_gdp['Gebietseinheit']) - set(df_pop['Kreisfreie Städte und Landkreise'])}\")\n",
    "\n",
    "# delete three rows not corresponding to districts in the population data\n",
    "df_pop = df_pop[~df_pop['Kreisfreie Städte und Landkreise'].str.contains('Mittelfranken', case=False, na=False)]\n",
    "df_pop = df_pop[~df_pop['Kreisfreie Städte und Landkreise'].str.contains('Unterfranken', case=False, na=False)]\n",
    "df_pop = df_pop[~df_pop['Kreisfreie Städte und Landkreise'].str.contains('Schwaben', case=False, na=False)]\n",
    "\n",
    "# check which districts are only contained in the bridge data\n",
    "print(f\"Districts contained only in bridge data: {set(df_bridges['Kreis']) - set(df_gdp['Gebietseinheit'])}\")\n",
    "\n",
    "# there is one district on the bridge data set (Eisenach) not contained in the other datasets due to the fact that it is an \n",
    "# old one, Eisenach nowadays belongs to Wartburgkreis\n",
    "df_bridges['Kreis'] = data_bridges['Kreis'].replace('Eisenach', 'Wartburgkreis')\n",
    "\n",
    "# check which districts are only contained in the bridge data or not contained in bridge data\n",
    "print(f\"Districts contained only in bridge data: {set(df_bridges['Kreis']) - set(df_gdp['Gebietseinheit'])}\")\n",
    "print(f\"Districts not contained in bridge data: {set(df_gdp['Gebietseinheit']) - set(df_bridges['Kreis'])}\")\n",
    "\n",
    "# print number of unique districts in each data set\n",
    "print(f\"Number unique districts POPULATION: {len(df_pop['Kreisfreie Städte und Landkreise'].unique())} (total: {len(df_pop)})\")\n",
    "print(f\"Number unique districts GDP: {len(df_gdp['Gebietseinheit'].unique())} (total: {len(df_gdp)})\")\n",
    "print(f\"Number unique districts BRIDGES: {len(df_bridges['Kreis'].unique())}\")\n",
    "\n",
    "print(f\"Districts that are not unique: {df_gdp['Gebietseinheit'].value_counts()[lambda x: x > 1].index.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ce87a",
   "metadata": {},
   "source": [
    "Because some cities occur more then once (because we deleted labels like `Kreis` and `Landkreis`) we have to merge those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1ace2db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in population data: Index(['Amtlicher Regionalschlüssel', 'Kreisfreie Städte und Landkreise',\n",
      "       'NUTS3', ' Fläche km² ¹⁾',\n",
      "       'Bevölkerung auf Grundlage des ZENSUS 2022 ²⁾ insgesamt',\n",
      "       'Bevölkerung auf Grundlage des ZENSUS 2022 ²⁾ männlich',\n",
      "       'Bevölkerung auf Grundlage des ZENSUS 2022 ²⁾ weiblich',\n",
      "       'Bevölkerung auf Grundlage des ZENSUS 2022 ²⁾ je km²'],\n",
      "      dtype='object')\n",
      "Columns in population data: Index(['Kreis', 'Code', 'Fläche (qkm)', 'Bevölkerung (insgesamt)',\n",
      "       'Bevölkerung (männlich)', 'Bevölkerung (weiblich)',\n",
      "       'Bevölkerung (je qkm)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_pop_norm = df_pop.copy()\n",
    "\n",
    "# rename columns in pop data set, remove unnecessary columns\n",
    "print(f\"Columns in population data: {df_pop_norm.columns}\")\n",
    "df_pop_norm = df_pop_norm.rename(columns={'NUTS3': 'Code', 'Kreisfreie Städte und Landkreise': 'Kreis', ' Fläche km² ¹⁾': 'Fläche (qkm)', 'Bevölkerung auf Grundlage des ZENSUS 2022 ²⁾ insgesamt': 'Bevölkerung (insgesamt)', 'Bevölkerung auf Grundlage des ZENSUS 2022 ²⁾ männlich': 'Bevölkerung (männlich)', 'Bevölkerung auf Grundlage des ZENSUS 2022 ²⁾ weiblich': 'Bevölkerung (weiblich)', 'Bevölkerung auf Grundlage des ZENSUS 2022 ²⁾ je km²': 'Bevölkerung (je qkm)'})\n",
    "df_pop_norm = df_pop_norm.drop(columns=['Amtlicher Regionalschlüssel'])\n",
    "print(f\"Columns in population data: {df_pop_norm.columns}\")\n",
    "\n",
    "# Merge data of cities with the same name due to normalisation. (Kassel Kreis, Kassel Landkreis)\n",
    "# Merge population\n",
    "columns_to_sum = [\n",
    "    'Fläche (qkm)',\n",
    "    'Bevölkerung (insgesamt)',\n",
    "    'Bevölkerung (männlich)',\n",
    "    'Bevölkerung (weiblich)',\n",
    "    'Bevölkerung (je qkm)'\n",
    "]\n",
    "\n",
    "# Group by 'Kreis' and sum all numeric columns\n",
    "df_pop_cleaned = df_pop_norm.groupby('Kreis', as_index=False)[columns_to_sum].sum()\n",
    "\n",
    "# save final population dataset\n",
    "df_pop_cleaned.to_csv('../data/population_dataset_cleaned.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171eb0a",
   "metadata": {},
   "source": [
    "To summarize the GDP for those districts, that include a district and a city, we need to know the population of both to be able to calculate the GDP of the combined district. This works as follows: \n",
    "\n",
    "GDP_combined_district = (GDP_district * Population_district + GDP_city * Population_city) / (Population_district + Population_city)\n",
    "\n",
    "Therefore, we need to add the information which row corresponds to the district and which to the city if there are multiple rows with the same district name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6569aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp_norm = df_gdp.copy()\n",
    "\n",
    "# rename columns in gdp data set and remove unnecesary ones\n",
    "#print(f\"Columns in GDP data: {df_gdp_norm.columns}\")\n",
    "df_gdp_norm = df_gdp_norm[['Gebietseinheit', 2022, 'EU-Code']]\n",
    "df_gdp_norm = df_gdp_norm.rename(columns={'Gebietseinheit': 'Kreis', 2022: 'GDP 2022', 'EU-Code': 'Code'})\n",
    "#print(f\"Columns in GDP data: {df_gdp_norm.columns}\")\n",
    "\n",
    "# list all district names occuring twice in the gdp data set\n",
    "districts = df_gdp_norm['Kreis'].value_counts()[lambda x: x > 1].index.tolist()\n",
    "\n",
    "# merge GDP\n",
    "# loop over all districts summarizing multiple districts/cities\n",
    "merged_dict = dict()\n",
    "for d_name in districts: \n",
    "    gdp = df_gdp_norm.loc[df_gdp_norm['Kreis'] == d_name]\n",
    "    pop = df_pop_norm.loc[df_pop_norm['Kreis'] == d_name]\n",
    "    merged = pd.merge(gdp, pop, on='Code')\n",
    "   \n",
    "    merged_gdp = (merged['Bevölkerung (insgesamt)'][0] * merged['GDP 2022'][0] + \n",
    "                  merged['Bevölkerung (insgesamt)'][1] * merged['GDP 2022'][1]) / (merged['Bevölkerung (insgesamt)'][0] + merged['Bevölkerung (insgesamt)'][1])\n",
    "    merged_dict[d_name] = merged_gdp\n",
    "\n",
    "# new GDP\n",
    "new_df_gdp = pd.DataFrame(columns=['Kreis', 'GDP 2022'])\n",
    "for i, row in df_gdp_norm.iterrows(): \n",
    "    district_name = row['Kreis']\n",
    "    if district_name in districts: \n",
    "        new_df_gdp.loc[len(new_df_gdp)] = [district_name, merged_dict[district_name]]\n",
    "    else: \n",
    "        new_df_gdp.loc[len(new_df_gdp)] = [district_name, df_gdp_norm.loc[df_gdp_norm['Kreis'] == district_name, 'GDP 2022'].iloc[0]]\n",
    "\n",
    "# remove duplicate rows\n",
    "df_gdp_cleaned = new_df_gdp.drop_duplicates(subset=['Kreis'])\n",
    "\n",
    "# save final gdp dataset\n",
    "df_gdp_cleaned.to_csv('../data/gdp_dataset_cleaned.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89722eb",
   "metadata": {},
   "source": [
    "Now we merge the corrected bridge dataset with the cleaned population and gdp dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9d9ea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46952\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# merge datasets\n",
    "gdp_pop = pd.merge(df_gdp_cleaned, df_pop_cleaned[['Kreis', 'Fläche (qkm)', 'Bevölkerung (insgesamt)']], on='Kreis', how='inner')\n",
    "final_dataset = pd.merge(df_bridges, gdp_pop, on='Kreis', how='inner')\n",
    "\n",
    "# save final dataset\n",
    "final_dataset.to_csv('../data/final_bridge_statistic_germany.csv', sep=';', index=False)\n",
    "\n",
    "print(len(final_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
